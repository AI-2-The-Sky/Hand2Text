{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nptyping in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.0.0 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from nptyping) (4.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from nptyping) (1.22.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nptyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (4.20.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages (from requests->transformers) (2022.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset\n",
    "import numpy as np\n",
    "from nptyping import Float32, NDArray, Number, Shape, UInt\n",
    "from transformers import ViTModel\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignedDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.Y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT_FeatureExtractor(pl.LightningModule):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tnb_classes: int = 10,\n",
    "\t):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# print(\"---VIT INIT---\")\n",
    "\n",
    "\t\tself.pretrained_vit = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "\t\tself.pretrained_vit.eval()\n",
    "\n",
    "\t\tself.conv_1d_1 = torch.nn.Conv1d(\n",
    "\t\t\tin_channels=197,\n",
    "\t\t\tout_channels=64,\n",
    "\t\t\tkernel_size=3,\n",
    "\t\t)\n",
    "\t\tself.layer_1_relu = nn.ReLU()\n",
    "\t\tself.conv_1d_2 = torch.nn.Conv1d(\n",
    "\t\t\tin_channels=64,\n",
    "\t\t\tout_channels=nb_classes, # <-- i/o 1\n",
    "\t\t\tkernel_size=3,\n",
    "\t\t)\n",
    "\t\tself.layer_2_relu = nn.ReLU()\n",
    "\n",
    "\tdef vit_extract_features(self, x):\n",
    "\t\t# print(\"---VIT EXTRACT FEATURES---\")\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\toutputs = self.pretrained_vit(pixel_values=x)\n",
    "\t\t\tvit_feat = outputs.last_hidden_state\n",
    "\t\t\tprint(f\"{vit_feat.shape= }\")\n",
    "\t\t\tvit_feat = torch.flatten(vit_feat, start_dim=1)\n",
    "\t\treturn vit_feat\n",
    "\t\n",
    "\tdef forward(\n",
    "\t\tself,\n",
    "\t\tvit_feat, \n",
    "\t) -> NDArray[Shape[\"* batch, * vocab size\"], Float32]:\n",
    "\t\t# print(\"---VIT FORWARD---\")\n",
    "\t\tx = self.conv_1d_1(vit_feat)\n",
    "\t\tx = self.layer_1_relu(x)\n",
    "\t\tx = self.conv_1d_2(x)\n",
    "\t\tx = self.layer_2_relu(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(pl.LightningModule):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t):\n",
    "\t\t# print(\"---BASIC MODEL INIT---\")\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.save_hyperparameters()\n",
    "\n",
    "\t\tself.vocabulary_size = nb_classes\n",
    "\t\tself.layer = nn.Linear(151296, self.vocabulary_size)\n",
    "\t\tself.softmax = torch.nn.Softmax(dim=2)\n",
    "\n",
    "\tdef forward(\n",
    "\t\tself, x: NDArray[Shape[\"* batch, 224, 224, 3\"], Float32]\n",
    "\t) -> NDArray[Shape[\"* batch, * vocab size\"], Float32]:\n",
    "\t\t# print(\"---BASIC MODEL FORWARD---\")\n",
    "\t\tx = self.layer(x)\n",
    "\t\tx = self.softmax(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Translator(pl.LightningModule):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tnb_classes,\n",
    "\t\tH_input_size: int = 151296,\n",
    "\t\tH_output_size: int = 100,\n",
    "\t\tnum_layers: int = 1,\n",
    "\t\tdropout: int = 0,\n",
    "\t):\n",
    "\t\t# print(\"---GRU INIT---\")\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.save_hyperparameters()\n",
    "\t\tself.vocabulary_size = nb_classes\n",
    "\t\tself.layer_gru = nn.GRU(\n",
    "\t\t\tinput_size=self.hparams.H_input_size,\n",
    "\t\t\thidden_size=self.hparams.nb_classes,\n",
    "\t\t\tnum_layers=self.hparams.num_layers,\n",
    "\t\t\tbatch_first=True,\n",
    "\t\t\tdropout=self.hparams.dropout,\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\t# self.layer_1_dense = nn.Linear(self.hparams.H_output_size, self.hparams.H_output_size)\n",
    "\t\t# self.layer_1_relu = nn.ReLU()\n",
    "\t\t# self.layer_2_dense = nn.Linear(self.hparams.H_output_size, self.vocabulary_size)\n",
    "\t\t# self.layer_2_relu = nn.ReLU()\n",
    "\t\tself.softmax = nn.Softmax(dim=2) # <-- i/o dim=2\n",
    "\n",
    "\tdef forward(self, X):\n",
    "\t\t# print(\"---GRU FORWARD---\")\t\n",
    "\t\t# print(f'{X.shape =}')\n",
    "\t\tX, _ = self.layer_gru(X)\n",
    "\t\t# X = self.layer_1_dense(X)\n",
    "\t\t# X = self.layer_1_relu(X)\n",
    "\t\t# X = self.layer_2_dense(X)\n",
    "\t\t# X = self.layer_2_relu(X)\n",
    "\t\t# print(f'{X.shape =}')\n",
    "\t\tX = self.softmax(X)\n",
    "\t\t# print(f'{X.shape =}')\n",
    "\t\treturn X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseSquareNet(pl.LightningModule):\n",
    "\tdef __init__(\n",
    "\t\tself,\n",
    "\t\tbatch_size: int = 1,\n",
    "\t\tseq_size: int = 1,\n",
    "\t\tnb_classes: int = 10,\n",
    "\t\th_in: int = 10,\n",
    "\t):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.save_hyperparameters()\n",
    "\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.nb_seq_sizebatch = seq_size\n",
    "\t\tself.image_feature_extractr = ViT_FeatureExtractor(nb_classes=nb_classes)\n",
    "\t\tself.recurrent_translator = GRU_Translator(\n",
    "\t\t\tnb_classes = nb_classes,\n",
    "\t\t\tH_input_size=h_in,\n",
    "\t\t\t# H_output_size=100,\n",
    "\t\t\tnum_layers=1,\n",
    "\t\t\tdropout=0,\n",
    "\t\t)\n",
    "\n",
    "\tdef forward(\n",
    "\t\tself, x: NDArray[Shape[\"* batch, 224, 224, 3\"], Float32]\n",
    "\t) -> NDArray[Shape[\"* batch, * vocab size\"], Float32]:\n",
    "\t\tx = self.recurrent_translator(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "nb_classes=1999\n",
    "seq_size = 16\n",
    "batch_size = 2\n",
    "learning_rate = 1e-3\n",
    "h_in = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.size()=torch.Size([2, 16])\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "# x = torch.rand((batch_size, seq_size, 3, 224, 224))\n",
    "# y = torch.randint(0, nb_classes, (batch_size, seq_size, 1))\n",
    "\n",
    "# x = torch.rand((batch_size, 3, 224, 224))\n",
    "x = torch.rand((batch_size, seq_size, h_in))\n",
    "y = torch.randint(0, nb_classes, (batch_size, seq_size))\n",
    "\n",
    "print(f\"{y.size()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "model = BaseSquareNet(nb_classes=nb_classes, seq_size=seq_size, batch_size=batch_size)\n",
    "# vit_feat = model.image_feature_extractr.vit_extract_features(x)\n",
    "\n",
    "# dataset = SignedDataset(vit_feat, y)\n",
    "dataset = SignedDataset(x, y)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(train_loader, model, loss_fn, optimizer):\n",
    "\tloss = 10\n",
    "\tidx = 0\n",
    "\twhile loss > 6.7:\n",
    "\t\tfor batch_idx, (X, y) in enumerate(train_loader):\n",
    "\t\t\tpred = model(X)\n",
    "\t\t\tpred = pred.permute(0, 2, 1)\n",
    "\t\t\tloss = loss_fn(pred, y)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\n",
    "\t\t\t# if idx % 10 == 0:\n",
    "\t\t\tprint(f'[{idx}] loss: {loss}')\n",
    "\t\t\tidx += 1\n",
    "\n",
    "\tprint(f'[{idx}] final loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] loss: 7.600401878356934\n",
      "[1] loss: 7.600377082824707\n",
      "[2] loss: 7.600338935852051\n",
      "[3] loss: 7.60021448135376\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/mcciupek/Documents/42/AI/Hand2Text/notebooks/overfit_basesquare_mc.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mcciupek/Documents/42/AI/Hand2Text/notebooks/overfit_basesquare_mc.ipynb#ch0000005?line=0'>1</a>\u001b[0m train(dataloader, model, loss_fn, optimizer)\n",
      "\u001b[1;32m/Users/mcciupek/Documents/42/AI/Hand2Text/notebooks/overfit_basesquare_mc.ipynb Cell 11'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mcciupek/Documents/42/AI/Hand2Text/notebooks/overfit_basesquare_mc.ipynb#ch0000004?line=18'>19</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mcciupek/Documents/42/AI/Hand2Text/notebooks/overfit_basesquare_mc.ipynb#ch0000004?line=19'>20</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mcciupek/Documents/42/AI/Hand2Text/notebooks/overfit_basesquare_mc.ipynb#ch0000004?line=20'>21</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mcciupek/Documents/42/AI/Hand2Text/notebooks/overfit_basesquare_mc.ipynb#ch0000004?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mcciupek/Documents/42/AI/Hand2Text/notebooks/overfit_basesquare_mc.ipynb#ch0000004?line=23'>24</a>\u001b[0m \u001b[39m# if idx % 10 == 0:\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[39m# record the step after step update\u001b[39;00m\n\u001b[1;32m    139\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     F\u001b[39m.\u001b[39;49madam(params_with_grad,\n\u001b[1;32m    142\u001b[0m            grads,\n\u001b[1;32m    143\u001b[0m            exp_avgs,\n\u001b[1;32m    144\u001b[0m            exp_avg_sqs,\n\u001b[1;32m    145\u001b[0m            max_exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m            state_steps,\n\u001b[1;32m    147\u001b[0m            amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    148\u001b[0m            beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    149\u001b[0m            beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    150\u001b[0m            lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    151\u001b[0m            weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m            eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m            maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    154\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/miniconda3/envs/Hand2Text/lib/python3.8/site-packages/torch/optim/_functional.py:105\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    103\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(bias_correction2))\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m math\u001b[39m.\u001b[39;49msqrt(bias_correction2))\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    109\u001b[0m step_size \u001b[39m=\u001b[39m lr \u001b[39m/\u001b[39m bias_correction1\n\u001b[1;32m    110\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(dataloader, model, loss_fn, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e5cf168e483d0a9ac2f5326c7238cfe4405c28e0dcf7dcfceeeb179bf0db248"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
